{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee488014-5b7a-42d3-81bb-5e01a5a8867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adjustText in c:\\users\\ariji\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from adjustText) (1.24.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from adjustText) (3.8.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from adjustText) (1.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from matplotlib->adjustText) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from matplotlib->adjustText) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from matplotlib->adjustText) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from matplotlib->adjustText) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from matplotlib->adjustText) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from matplotlib->adjustText) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from matplotlib->adjustText) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from matplotlib->adjustText) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->adjustText) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install adjustText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02aedc13-0838-4a4d-a78b-99298c44fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "import zipfile\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn.manifold import TSNE\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a0578-48a6-4654-a22d-1d79bde8f880",
   "metadata": {},
   "source": [
    "# 1. Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22357c97-3b3c-4a4e-8b8a-3ee92a7b2a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file...\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
    "\n",
    "\n",
    "def download_data(url, data_dir):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print('Downloading file...')\n",
    "        filename, _ = urlretrieve(url, file_path)\n",
    "    else:\n",
    "        print(\"File already exists\")\n",
    "\n",
    "    extract_path = os.path.join(data_dir, 'bbc')\n",
    "    if not os.path.exists(extract_path):\n",
    "\n",
    "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf:\n",
    "            zipf.extractall(data_dir)\n",
    "\n",
    "    else:\n",
    "        print(\"bbc-fulltext.zip has already been extracted\")\n",
    "\n",
    "download_data(url, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae3615-cbe4-42ea-8558-afbfc90a4d85",
   "metadata": {},
   "source": [
    "# 2. Reading the data without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dfe8a99-d03c-4ce9-8195-ccf3d35e84ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 401.txt\n",
      "Detected 2225 stories\n",
      "865163 words found in the total news set\n",
      "Example words (start):  Ad sales boost Time Warner profit  Quarterly profi\n",
      "Example words (end):  Online was the game, ahhhh them was the days ! LOL\n"
     ]
    }
   ],
   "source": [
    "def read_data(data_dir):\n",
    "\n",
    "    # This will contain the full list of stories\n",
    "    news_stories = []\n",
    "\n",
    "    print(\"Reading files\")\n",
    "\n",
    "    i = 0 # Just used for printing progress\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "\n",
    "        for fi, f in enumerate(files):\n",
    "\n",
    "            # We don't read the README file\n",
    "            if 'README' in f:\n",
    "                continue\n",
    "\n",
    "            # Printing progress\n",
    "            i += 1\n",
    "            print(\".\"*i, f, end='\\r')\n",
    "\n",
    "            # Open the file\n",
    "            with open(os.path.join(root, f), encoding='latin-1') as f:\n",
    "\n",
    "                story = []\n",
    "                # Read all the lines\n",
    "                for row in f:\n",
    "\n",
    "                    story.append(row.strip())\n",
    "\n",
    "                # Create a single string with all the rows in the doc\n",
    "                story = ' '.join(story)\n",
    "                # Add that to the list\n",
    "                news_stories.append(story)\n",
    "\n",
    "        print('', end='\\r')\n",
    "\n",
    "    print(f\"\\nDetected {len(news_stories)} stories\")\n",
    "    return news_stories\n",
    "\n",
    "\n",
    "news_stories = read_data(os.path.join('data', 'bbc'))\n",
    "\n",
    "# Printing some stats and sample data\n",
    "print(f\"{sum([len(story.split(' ')) for story in news_stories])} words found in the total news set\")\n",
    "print('Example words (start): ',news_stories[0][:50])\n",
    "print('Example words (end): ',news_stories[-1][-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e0d74-0146-4207-ba72-fcaff29dd3b9",
   "metadata": {},
   "source": [
    "# 3. Building a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45f8ba0c-4719-4ee3-aa14-f218d1835d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fitted on the tokenizer\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=None,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' '\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(news_stories)\n",
    "print(\"Data fitted on the tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13f538-71fd-4384-8653-4d1dbccf956b",
   "metadata": {},
   "source": [
    "# 4. Exploring the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f88b2c4a-43f2-4087-8f3b-567fcd728c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 32360\n",
      "\n",
      "Words at the top\n",
      "\t {'the': 1, 'to': 2, 'of': 3, 'and': 4, 'a': 5, 'in': 6, 'for': 7, 'is': 8, 'that': 9, 'on': 10}\n",
      "\n",
      "Words at the bottom\n",
      "\t {'counsellor': 32350, \"'frag'\": 32351, 'relasing': 32352, \"'real'\": 32353, 'hrs': 32354, 'enviroment': 32355, 'trifling': 32356, '24hours': 32357, 'ahhhh': 32358, 'lol': 32359}\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(tokenizer.word_index.items()) + 1\n",
    "print(f\"Vocabulary size: {n_vocab}\")\n",
    "\n",
    "print(\"\\nWords at the top\")\n",
    "print('\\t', dict(list(tokenizer.word_index.items())[:10]))\n",
    "print(\"\\nWords at the bottom\")\n",
    "print('\\t', dict(list(tokenizer.word_index.items())[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca274d-e1d9-4f21-b1ea-5b5042681aa6",
   "metadata": {},
   "source": [
    "# 5. Building a refined tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b101f1-85f1-4e99-983d-e4c918fdd6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fitted on the tokenizer\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "n_vocab = 15000 + 1\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=n_vocab-1,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', oov_token='',\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(news_stories)\n",
    "print(\"Data fitted on the tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d54fc-f107-428b-bdfd-a44c0f2b50da",
   "metadata": {},
   "source": [
    "# 6. Checking the results of the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37ef75ce-98c4-48c4-8d19-6851ac674473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Ad sales boost Time Warner profit  Quarterly profits at US media giant TimeWarner jumped 76% to $1.1\n",
      "Sequence IDs: [4223, 187, 716, 66, 3596, 1050, 3938, 626, 21, 49, 303, 717, 8263, 2972, 5321, 3, 108, 108]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original: {news_stories[0][:100]}\")\n",
    "print(f\"Sequence IDs: {tokenizer.texts_to_sequences([news_stories[0][:100]])[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc55ae4-b254-4e6a-b688-29450c23e3ef",
   "metadata": {},
   "source": [
    "# 7. Converting all articles to word ID sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e48e0cc0-f099-464d-a516-6c9c2107c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_sequences = tokenizer.texts_to_sequences(news_stories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4cb45d-4a97-469b-b6fa-730ceb7d7b1c",
   "metadata": {},
   "source": [
    "# 8. Generating skip-grams from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e9f094-3ed7-4ef5-9460-5370570e4f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample phrase: ad sales boost time warner\n",
      "Sample word IDs: [4223, 187, 716, 66, 3596]\n",
      "\n",
      "Sample skip-grams\n",
      "\tInput: [4223, 187] (['ad', 'sales']) / Label: 1\n",
      "\tInput: [187, 4223] (['sales', 'ad']) / Label: 1\n",
      "\tInput: [187, 716] (['sales', 'boost']) / Label: 1\n",
      "\tInput: [716, 187] (['boost', 'sales']) / Label: 1\n",
      "\tInput: [716, 66] (['boost', 'time']) / Label: 1\n",
      "\tInput: [66, 716] (['time', 'boost']) / Label: 1\n",
      "\tInput: [66, 3596] (['time', 'warner']) / Label: 1\n",
      "\tInput: [3596, 66] (['warner', 'time']) / Label: 1\n",
      "\tInput: [4223, 11275] (['ad', 'instability']) / Label: 0\n",
      "\tInput: [187, 6894] (['sales', 'merit']) / Label: 0\n",
      "\tInput: [3596, 4062] (['warner', 'cinemas']) / Label: 0\n",
      "\tInput: [716, 12161] (['boost', 'chaplin']) / Label: 0\n",
      "\tInput: [187, 10395] (['sales', 'destiny']) / Label: 0\n",
      "\tInput: [716, 3285] (['boost', 'parker']) / Label: 0\n",
      "\tInput: [66, 5499] (['time', 'incredibles']) / Label: 0\n",
      "\tInput: [66, 10219] (['time', 'buccaneers']) / Label: 0\n"
     ]
    }
   ],
   "source": [
    "sample_word_ids = news_sequences[0][:5]\n",
    "sample_phrase = ' '.join([tokenizer.index_word[wid] for wid in sample_word_ids])\n",
    "print(f\"Sample phrase: {sample_phrase}\")\n",
    "print(f\"Sample word IDs: {sample_word_ids}\\n\")\n",
    "\n",
    "window_size = 1 # How many words to consider left and right.\n",
    "\n",
    "inputs, labels = tf.keras.preprocessing.sequence.skipgrams(\n",
    "    sample_word_ids,\n",
    "    vocabulary_size=n_vocab,\n",
    "    window_size=window_size, negative_samples=1.0, shuffle=False,\n",
    "    categorical=False, sampling_table=None, seed=None\n",
    ")\n",
    "\n",
    "print(\"Sample skip-grams\")\n",
    "\n",
    "for inp, lbl in zip(inputs, labels):\n",
    "    print(f\"\\tInput: {inp} ({[tokenizer.index_word[wi] for wi in inp]}) / Label: {lbl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4f5a5-92ac-4cc3-9297-a982849ee3b3",
   "metadata": {},
   "source": [
    "# 9. Generating negative candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2c34f21-e909-48e2-8129-8a33b89a0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sample: [[187]]\n",
      "Negative samples: [   7  390 1336    0   98   78 7943 1701 6331 1507]\n",
      "true_expected_count: [[0.00605192]]\n",
      "sampled_expected_count: [1.2678023e-01 2.9180504e-03 8.5494545e-04 5.6086338e-01 1.1437029e-02\n",
      " 1.4295553e-02 1.4398129e-04 6.7170913e-04 1.8063012e-04 7.5806427e-04]\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = tf.keras.preprocessing.sequence.skipgrams(\n",
    "    sample_word_ids,\n",
    "    vocabulary_size=len(tokenizer.word_index.items())+1,\n",
    "    window_size=window_size, negative_samples=0, shuffle=False,\n",
    ")\n",
    "\n",
    "inputs, labels = np.array(inputs), np.array(labels)\n",
    "\n",
    "negative_sampling_candidates, true_expected_count, sampled_expected_count = tf.random.log_uniform_candidate_sampler(\n",
    "    # A true context word that appears in the context of the target\n",
    "    true_classes=inputs[:1,1:], # [b, 1] sized tensor\n",
    "    num_true=1, # number of true words per example\n",
    "    num_sampled=10,\n",
    "    unique=True,\n",
    "    range_max=n_vocab,\n",
    "    name=\"negative_sampling\"\n",
    ")\n",
    "\n",
    "print(f\"Positive sample: {inputs[:1,1:]}\")\n",
    "print(f\"Negative samples: {negative_sampling_candidates}\")\n",
    "print(f\"true_expected_count: {true_expected_count}\")\n",
    "print(f\"sampled_expected_count: {sampled_expected_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc31d47f-70ff-4de9-ba79-ae7637da3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(n_vocab, sampling_factor=1e-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe21b56-1811-4704-be82-dd8d3357745a",
   "metadata": {},
   "source": [
    "# 10. Generating data ( positive + negative candidates )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f3139c-a834-4731-b203-f0a669a4821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 3369,  8176, 10982, 10981,   817,   798,  2469,  2963,  3796,\n",
      "        2469]), array([   4, 2169,   21,    8, 2004,  539,    0, 2157,   61,   35],\n",
      "      dtype=int64))\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def skip_gram_data_generator(sequences, window_size, batch_size, negative_samples, vocab_size, seed=None):\n",
    "\n",
    "    rand_sequence_ids = np.arange(len(sequences))\n",
    "    np.random.shuffle(rand_sequence_ids)\n",
    "\n",
    "\n",
    "    for si in rand_sequence_ids:\n",
    "\n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "            sequences[si],\n",
    "            vocabulary_size=vocab_size,\n",
    "            window_size=window_size,\n",
    "            negative_samples=0.0,\n",
    "            shuffle=False,\n",
    "            sampling_table=sampling_table,\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "        targets, contexts, labels = [], [], []\n",
    "\n",
    "        for target_word, context_word in positive_skip_grams:\n",
    "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "\n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "              true_classes=context_class,\n",
    "              num_true=1,\n",
    "              num_sampled=negative_samples,\n",
    "              unique=True,\n",
    "              range_max=vocab_size,\n",
    "              name=\"negative_sampling\")\n",
    "\n",
    "            # Build context and label vectors (for one target word)\n",
    "            context = tf.concat(\n",
    "                [tf.constant([context_word], dtype='int64'), negative_sampling_candidates],\n",
    "                axis=0\n",
    "            )\n",
    "\n",
    "            label = tf.constant([1] + [0]*negative_samples, dtype=\"int64\")\n",
    "\n",
    "            # Append each element from the training example to global lists.\n",
    "            targets.extend([target_word]*(negative_samples+1))\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "\n",
    "        contexts, targets, labels = np.concatenate(contexts), np.array(targets), np.concatenate(labels)\n",
    "\n",
    "        assert contexts.shape[0] == targets.shape[0]\n",
    "        assert contexts.shape[0] == labels.shape[0]\n",
    "\n",
    "        # If seed is not provided, generate a random one\n",
    "        if not seed:\n",
    "            seed = random.randint(0, 10e6)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(contexts)\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(targets)\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(labels)\n",
    "\n",
    "\n",
    "        for eg_id_start in range(0, contexts.shape[0], batch_size):\n",
    "            yield (\n",
    "                targets[eg_id_start: min(eg_id_start+batch_size, targets.shape[0])],\n",
    "                contexts[eg_id_start: min(eg_id_start+batch_size, contexts.shape[0])]\n",
    "            ), labels[eg_id_start: min(eg_id_start+batch_size, labels.shape[0])]\n",
    "\n",
    "\n",
    "news_skip_gram_gen = skip_gram_data_generator(\n",
    "    news_sequences, 4, 10, 5, n_vocab\n",
    ")\n",
    "\n",
    "for btc, bl in news_skip_gram_gen:\n",
    "\n",
    "    print(btc)\n",
    "    print(bl)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da11611-4f53-464b-9d28-73e47ebc6428",
   "metadata": {},
   "source": [
    "# 11. Defining the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ab33ff8-9233-48a1-8ae3-e0ba8608d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096 # Data points in a single batch\n",
    "\n",
    "embedding_size = 128 # Dimension of the embedding vector.\n",
    "\n",
    "window_size=1 # We use a window size of n on either side of target word\n",
    "negative_samples = 4 # Number of negative samples generated per example\n",
    "\n",
    "epochs = 5 # Number of epochs to train for\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors\n",
    "valid_size = 16 # Random set of words to evaluate similarity on.\n",
    "# We sample valid data points randomly from a large window without always being deterministic\n",
    "valid_window = 250\n",
    "\n",
    "# When selecting valid examples, we select some of the most frequent words as well as\n",
    "# some moderately rare words\n",
    "np.random.seed(54321)\n",
    "random.seed(54321)\n",
    "\n",
    "valid_term_ids = np.array(random.sample(range(valid_window), valid_size))\n",
    "valid_term_ids = np.append(\n",
    "    valid_term_ids, random.sample(range(1000, 1000+valid_window), valid_size),\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf834e9-7a8c-44b5-98a7-7b5a770ae33c",
   "metadata": {},
   "source": [
    "# 12. Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6da0a74-de89-43d6-b2d4-d66ae5cb58bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ariji\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"skip_gram_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"skip_gram_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ context             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ target (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ context_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,128</span> │ context[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ target_embedding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,128</span> │ target[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ context_embeddin… │\n",
       "│                     │                   │            │ target_embedding… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ context             │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ target (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ context_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m1,920,128\u001b[0m │ context[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ target_embedding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m1,920,128\u001b[0m │ target[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ context_embeddin… │\n",
       "│                     │                   │            │ target_embedding… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,256</span> (14.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,840,256\u001b[0m (14.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,256</span> (14.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,840,256\u001b[0m (14.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Inputs - skipgrams() function outputs target, context in that order\n",
    "# we will use the same order\n",
    "input_1 = tf.keras.layers.Input(shape=(), name='target')\n",
    "input_2 = tf.keras.layers.Input(shape=(), name='context')\n",
    "\n",
    "# Two embeddings layers are used, one for the context and one for the target\n",
    "context_embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=n_vocab, output_dim=embedding_size, name='context_embedding'\n",
    ")\n",
    "target_embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=n_vocab, output_dim=embedding_size, name='target_embedding'\n",
    ")\n",
    "\n",
    "# Look up outputs of the embedding layers\n",
    "target_out = target_embedding_layer(input_1)\n",
    "context_out = context_embedding_layer(input_2)\n",
    "\n",
    "# Computing the dot product between the two\n",
    "out = tf.keras.layers.Dot(axes=-1)([context_out, target_out])\n",
    "\n",
    "# Defining the model\n",
    "skip_gram_model = tf.keras.models.Model(inputs=[input_1, input_2],\n",
    "                                        outputs=out, name='skip_gram_model')\n",
    "\n",
    "# Compiling the model\n",
    "skip_gram_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                        optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "skip_gram_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fef3772-acae-4356-951a-6c5d0b407d8d",
   "metadata": {},
   "source": [
    "# 13. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e068d145-9857-4941-99b0-013e46f4bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, valid_term_ids, model_with_embeddings, tokenizer):\n",
    "\n",
    "        self.valid_term_ids = valid_term_ids\n",
    "        self.model_with_embeddings = model_with_embeddings\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\" Validation logic \"\"\"\n",
    "\n",
    "        # We will use context embeddings to get the most similar words\n",
    "        # Other strategies include: using target embeddings, mean embeddings after avaraging context/target\n",
    "        embedding_weights = self.model_with_embeddings.get_layer(\"context_embedding\").get_weights()[0]\n",
    "        normalized_embeddings = embedding_weights / np.sqrt(np.sum(embedding_weights**2, axis=1, keepdims=True))\n",
    "\n",
    "        # Get the embeddings corresponding to valid_term_ids\n",
    "        valid_embeddings = normalized_embeddings[self.valid_term_ids, :]\n",
    "\n",
    "        # Compute the similarity between valid_term_ids and all the embeddings\n",
    "        # V x d (d x D) => V x D\n",
    "        top_k = 5 # Top k items will be displayed\n",
    "        similarity = np.dot(valid_embeddings, normalized_embeddings.T)\n",
    "\n",
    "        # Invert similarity matrix to negative\n",
    "        # Ignore the first one because that would be the same word as the probe word\n",
    "        similarity_top_k = np.argsort(-similarity, axis=1)[:, 1: top_k+1]\n",
    "\n",
    "        # Print the output\n",
    "        for i, term_id in enumerate(valid_term_ids):\n",
    "\n",
    "            similar_word_str = ', '.join([self.tokenizer.index_word[j] for j in similarity_top_k[i, :] if j >= 1])\n",
    "            print(f\"{self.tokenizer.index_word[term_id]}: {similar_word_str}\")\n",
    "\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed4351-debf-48c5-b6c8-a3beb1807fc7",
   "metadata": {},
   "source": [
    "# 14. Running the skip-gram algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e58332ec-5cb8-4eb1-8854-206e48f645d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 started\n",
      "   2233/Unknown \u001b[1m85s\u001b[0m 38ms/step - accuracy: 0.8001 - loss: 0.6272election: promise, elliot, look, decline, fill\n",
      "me: ability, lot, bafta, result, him\n",
      "with: or, over, against, jealous, switzerland\n",
      "you: them, him, do, just, we\n",
      "were: already, now, have, do, did\n",
      "win: attempting, 2003, produce, work, want\n",
      "those: named, lot, ensure, used, work\n",
      "music: â£21m, misled, slashed, seafarers, games\n",
      "also: already, now, do, she, did\n",
      "third: second, edge, taken, conduct\n",
      "best: 1997, ignore, tight, appears, capability\n",
      "him: them, help, look, me, forsyth\n",
      "too: challenge, better, way, resolved, ensure\n",
      "some: quest, peak, way, charge\n",
      "through: come, ensure, produce, get\n",
      "mr: tony, said, gordon, jack, charles\n",
      "file: dominates, fabulous, mainstay, someone, affected\n",
      "pair: kind, chance, release, keypad, nothing\n",
      "ceremony: wanted, sure, able, democracy, capable\n",
      "believed: lot, trying, better, chance, decision\n",
      "post: way, peak, lot, wake, sure\n",
      "indian: island, prescott, hosford, times, released\n",
      "successful: demonstrates, leaders, due, provided, look\n",
      "care: temptation, relationship, appears, tend, region\n",
      "russia: chance, gprs, taken, reporters, work\n",
      "talk: lot, due, offices, intended, ability\n",
      "programs: peak, discuss, concentrating, work, possibility\n",
      "fair: megabits, trying, charities, likes, way\n",
      "hollywood: week, part, kind, chance, way\n",
      "attempt: lot, kind, fill, fact\n",
      "leave: appeal, lot, bafta, able, victims\n",
      "light: celebrity, easy, 2006, misled, bunch\n",
      "\n",
      "\n",
      "\u001b[1m2233/2233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 38ms/step - accuracy: 0.8001 - loss: 0.6272\n",
      "Epoch: 2/5 started\n",
      "      1/Unknown \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8085 - loss: 0.4489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariji\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2233/Unknown \u001b[1m84s\u001b[0m 37ms/step - accuracy: 0.8059 - loss: 0.4579election: advertising, broad, 1997, anticipated, consulates\n",
      "me: him, squandered, achieving, things, probably\n",
      "with: between, stringer, tanks, over, or\n",
      "you: we, they, don't, doesn't, didn't\n",
      "were: are, being, have, already, been\n",
      "win: attempting, mention, cheapest, survive, backbenchers\n",
      "those: publish, encouraged, shore, treasure, navigation\n",
      "music: games, women's, extended, sought, entertainment\n",
      "also: already, never, previously, widely, being\n",
      "third: fourth, second, premiere, historic, recruitment\n",
      "best: supporting, roles, association, title, actor\n",
      "him: me, them, didn't, things, probably\n",
      "too: extremely, better, easier, councillors, very\n",
      "some: overwhelming, value, dates, potential, petrov\n",
      "through: tactically, lvmh, zheng, gonna, obscene\n",
      "mr: tony, charles, jack, said, michael\n",
      "file: privately, centres, hosts, properties, hilarious\n",
      "pair: hampered, verge, objections, 2014, stolen\n",
      "ceremony: ignored, series, â£15, criticised, magnificent\n",
      "believed: borrow, trying, intend, wheelies, veto\n",
      "post: towns, 1970, principle, dozen, mafia\n",
      "indian: island, tidal, watch, times, kingfisher\n",
      "successful: indications, forefront, copying, realise, stoica\n",
      "care: laughing, toilet, heel, li, suspicions\n",
      "russia: abandonment, ai, barred, floor, striving\n",
      "talk: embrace, intended, lot, resolved, zombie\n",
      "programs: exacerbated, user's, podcasters, tide, lights\n",
      "fair: defend, fiasco, qualifiers, tgwu, mixes\n",
      "hollywood: training, edited, tables, feelings, tuesday\n",
      "attempt: thrust, portability, luck, practice, obscured\n",
      "leave: you've, druyun, glamour, ids, deported\n",
      "light: amplify, misled, qualms, mentions, defy\n",
      "\n",
      "\n",
      "\u001b[1m2233/2233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 38ms/step - accuracy: 0.8059 - loss: 0.4579\n",
      "Epoch: 3/5 started\n",
      "   2233/Unknown \u001b[1m85s\u001b[0m 38ms/step - accuracy: 0.8147 - loss: 0.4164election: advertising, extraordinary, promise, consulates, conspiracy\n",
      "me: him, things, squandered, toshiba, achieving\n",
      "with: between, press, bbc's, backwards, relaxation\n",
      "you: we, they, don't, you're, didn't\n",
      "were: are, been, have, being, formally\n",
      "win: tumbled, halifax, survive, megabytes, honoured\n",
      "those: shouldn't, constantly, aviator's, publish, euthanasia\n",
      "music: entertainment, games, snooker, content, audio\n",
      "also: already, previously, we've, now, actually\n",
      "third: fourth, second, fifth, side's, historic\n",
      "best: supporting, category, roles, heirs, association\n",
      "him: me, them, probably, properly, didn't\n",
      "too: extremely, very, so, better, incredibly\n",
      "some: millions, overwhelming, bonus, particular, sends\n",
      "through: couples, â£35bn, viewer, onto, motorsport\n",
      "mr: tony, jack, charles, gordon, gerhard\n",
      "file: networks, permanently, centres, fundamentally, originality\n",
      "pair: lodge, 2014, preparing, plenty, possibilities\n",
      "ceremony: series, grammy, deeley, dragged, list\n",
      "believed: adjust, implications, mount, doubtful, nas\n",
      "post: eagles, towns, westminster, brother's, cosla\n",
      "indian: island, tidal, indonesia, watch, kingfisher\n",
      "successful: lightly, tempered, exception, imply, representatives\n",
      "care: helping, forget, targeting, surely, wisdom\n",
      "russia: stubbs, sibneft, here's, ai, slides\n",
      "talk: taxation, podcasters, lasted, journeys, bow\n",
      "programs: user's, exacerbated, monitors, references, respected\n",
      "fair: destroy, repayments, soar, mmorpgs, knock\n",
      "hollywood: edited, day's, junior, series, rotterdam\n",
      "attempt: practice, inclusion, merrill's, dragged, sentimental\n",
      "leave: semis, interact, legality, sensors, improvise\n",
      "light: amplify, stockpiles, optical, bridges, exporter\n",
      "\n",
      "\n",
      "\u001b[1m2233/2233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 38ms/step - accuracy: 0.8147 - loss: 0.4164\n",
      "Epoch: 4/5 started\n",
      "   2233/Unknown \u001b[1m84s\u001b[0m 37ms/step - accuracy: 0.8250 - loss: 0.3859election: advertising, sums, guides, headquarters, promise\n",
      "me: him, them, reader, things, god\n",
      "with: relaxation, press, between, backwards, uncertainties\n",
      "you: we, don't, they, you're, didn't\n",
      "were: are, formally, being, been, have\n",
      "win: 600, halifax, catastrophe, honoured, michels\n",
      "those: affluent, isn't, constantly, euthanasia, competitors\n",
      "music: gprs, audio, gaming, subscriber, blip\n",
      "also: already, previously, repeatedly, we've, firmly\n",
      "third: fourth, second, fifth, sixth, first\n",
      "best: supporting, category, boxer, wars, gong\n",
      "him: me, them, briefly, properly, reader\n",
      "too: extremely, very, better, so, incredibly\n",
      "some: millions, compelling, licensing, particular, bonus\n",
      "through: onto, couples, â£35bn, asbestos, invention\n",
      "mr: jack, tony, charles, gerhard, eliot\n",
      "file: copyrighted, programs, originality, gain, centres\n",
      "pair: chalone, toshiba, mido, 2014, aurora\n",
      "ceremony: series, deeley, households, economies, brit\n",
      "believed: helpful, mount, regarded, dismantled, streamed\n",
      "post: eagles, brother's, gloom, commemoration, specifications\n",
      "indian: island, tidal, indonesia, arrival, honours\n",
      "successful: catchy, reinsurance, iconic, exception, lightly\n",
      "care: invading, discuss, forget, lasted, qualify\n",
      "russia: dod, cheer, angelina, sibneft, 1952\n",
      "talk: generate, punished, do', survive, bow\n",
      "programs: monitors, user's, invite, content, files\n",
      "fair: repayments, destroy, supermarket, criteria, workforce\n",
      "hollywood: honour, series, delhi, studio, brazil's\n",
      "attempt: joystick, structures, looming, reformed, skill\n",
      "leave: exploit, interact, suppose, seventies, legality\n",
      "light: amplify, exporter, bridges, optical, stockpiles\n",
      "\n",
      "\n",
      "\u001b[1m2233/2233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 37ms/step - accuracy: 0.8250 - loss: 0.3859\n",
      "Epoch: 5/5 started\n",
      "   2233/Unknown \u001b[1m85s\u001b[0m 38ms/step - accuracy: 0.8345 - loss: 0.3595election: labour's, larsson, helicopter, poster, broad\n",
      "me: him, them, things, adequately, briefly\n",
      "with: relaxation, atlantic, backwards, viotti's, visuals\n",
      "you: we, we'll, tonight, don't, you're\n",
      "were: are, formally, those, amid, been\n",
      "win: heirs, cigarettes, 000m, smashed, grabbed\n",
      "those: affluent, urgently, constantly, euthanasia, anyone\n",
      "music: unlimited, apple's, itunes, mp3, blip\n",
      "also: already, previously, repeatedly, firmly, allegedly\n",
      "third: fourth, second, fifth, seventh, sixth\n",
      "best: supporting, category, boxer, nomination, heirs\n",
      "him: me, them, anyone, briefly, she's\n",
      "too: extremely, very, incredibly, relatively, so\n",
      "some: millions, compelling, perfect, particular, darker\n",
      "through: onto, couples, â£35bn, exemptions, technicians\n",
      "mr: jack, tony, acknowledged, feroz, charles\n",
      "file: copyrighted, programs, illegally, routine, product\n",
      "pair: toshiba, shareholding, detentions, oecd, mido\n",
      "ceremony: series, hitch, deeley, opened, representatives\n",
      "believed: helpful, credited, regarded, beijing's, pretending\n",
      "post: brother's, eu's, gloom, eagles, laying\n",
      "indian: island, tidal, indonesia, presidency, honours\n",
      "successful: iconic, vulnerable, catchy, mission, respected\n",
      "care: invading, discuss, resentment, qualify, hanson\n",
      "russia: cellnet, doldrums, dod, americas, angelina\n",
      "talk: outraged, frightened, forget, survive, generate\n",
      "programs: content, monitors, innovative, mp3, smart\n",
      "fair: destroy, excess, barriers, waverley, tailored\n",
      "hollywood: delhi, honour, day's, ballad, junior\n",
      "attempt: barrier, chunk, skill, significance, influences\n",
      "leave: guaranteed, exploit, privately, refuses, interact\n",
      "light: bridges, amplify, pulses, exporter, continuous\n",
      "\n",
      "\n",
      "\u001b[1m2233/2233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 38ms/step - accuracy: 0.8345 - loss: 0.3595\n"
     ]
    }
   ],
   "source": [
    "skipgram_validation_callback = ValidationCallback(valid_term_ids, skip_gram_model, tokenizer)\n",
    "\n",
    "for ei in range(epochs):\n",
    "\n",
    "    print(f\"Epoch: {ei+1}/{epochs} started\")\n",
    "\n",
    "    news_skip_gram_gen = skip_gram_data_generator(\n",
    "        news_sequences, window_size, batch_size, negative_samples, n_vocab\n",
    "    )\n",
    "\n",
    "    skip_gram_model.fit(\n",
    "        news_skip_gram_gen, epochs=1,\n",
    "        callbacks=skipgram_validation_callback,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa98a51-e3f4-40be-b9ef-a97757627555",
   "metadata": {},
   "source": [
    "# 15. Usecase 1 : Visualize the word embeddings of some words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "255f9170-bc71-44ea-9c1b-0aa9265b6ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "[ 0.22746673  0.07138389  0.11764798  0.03281855 -0.21460196 -0.5240372\n",
      " -0.3249284   0.23186986 -0.204936    0.14132696 -0.09498704 -0.4589789\n",
      " -0.19136354  0.22529069  0.31748393 -0.15478028 -0.12603697 -0.06850798\n",
      " -0.33499986  0.09418409 -0.1837122  -0.06763232 -0.06832171 -0.13301939\n",
      "  0.16878468  0.19128338  0.0676093   0.13918488 -0.2992557  -0.13232473\n",
      "  0.04048631 -0.26357535  0.42646378  0.6451285   0.46789193  0.13119088\n",
      " -0.4487828  -0.15849559 -0.31067586  0.19438551  0.05548285 -0.16670148\n",
      " -0.6951338  -0.14330108  0.50013965  0.20417349 -0.03738758 -0.09156351\n",
      "  0.02752526  0.524384    0.0429455   0.08014193 -0.06908175 -0.15712656\n",
      " -0.06504448  0.17285568  0.5792302   0.04035402  0.09936652 -0.11419605\n",
      "  0.04411833  0.03865562  0.17002721 -0.32316512  0.5061779   0.06208441\n",
      "  0.01708469 -0.07603393 -0.7451564   0.10636906  0.06881762  0.29216084\n",
      " -0.01405409  0.34407157  0.16130112  0.07232776  0.07603461  0.3722347\n",
      "  0.5033964  -0.21041484  0.11422145  0.32182866  0.00656491 -0.1003104\n",
      "  0.15040909 -0.02307056 -0.16391349 -0.07296961  0.02894054 -0.64131784\n",
      " -0.0624626  -0.08524748  0.24516287 -0.10018213  0.37118527  0.04972099\n",
      "  0.19582023 -0.08034959  0.06605899  0.19505394  0.1498149   0.20078838\n",
      " -0.0098417  -0.0349822  -0.21188563 -0.23870382  0.13476492  0.15368491\n",
      " -0.0267235  -0.31609252  0.32254255 -0.16683985  0.21285178  0.06282359\n",
      "  0.03632161 -0.09737873 -0.18220088  0.00997481 -0.15859386  0.05002154\n",
      "  0.5938327   0.0313457   0.31212884  0.50994676 -0.37127304 -0.290248\n",
      " -0.0516961  -0.07199751]\n"
     ]
    }
   ],
   "source": [
    "# example 1 : word vector for \"dog\"\n",
    "word_vector_dog = skip_gram_model.get_layer(\"context_embedding\").get_weights()[0][tokenizer.word_index[\"dog\"]]\n",
    "\n",
    "print(len(word_vector_dog))\n",
    "print(word_vector_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bfd6c26-cb67-45a5-894f-44596d0b0f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "[ 0.22118916  0.1273138   0.13676815  0.3060822   0.08332124 -0.18960623\n",
      " -0.2369323   0.23993364 -0.37014     0.3379539  -0.20337565 -0.30013242\n",
      "  0.24026766  0.26052666 -0.08621705  0.13927417  0.17124383  0.12321689\n",
      " -0.14217646 -0.2471389  -0.16004278 -0.38916877  0.13592231 -0.274355\n",
      "  0.25753668  0.24689075 -0.08672582  0.21177335 -0.02355324 -0.13768663\n",
      "  0.06724598 -0.12024601  0.1784991   0.17655182  0.15259972  0.16850936\n",
      " -0.23959818 -0.18561083 -0.12562609  0.21827549  0.1752871  -0.24447939\n",
      "  0.01715354 -0.2675737   0.13125795 -0.00123536  0.2473496  -0.16863863\n",
      " -0.10351441  0.18114561  0.4576279  -0.18226895 -0.28612912  0.0771334\n",
      "  0.10465913  0.1921185   0.09149513 -0.07210246  0.05147637  0.07265592\n",
      " -0.25594163 -0.13637617  0.25891873 -0.17306577 -0.14051317  0.34425125\n",
      "  0.20302482  0.10817692 -0.17956921  0.20847966  0.3505246  -0.01836295\n",
      "  0.15275636  0.3135562   0.22703566 -0.33653134  0.22314174  0.27401575\n",
      "  0.07934818 -0.3662857   0.03376219  0.19614582  0.05497822  0.13558489\n",
      " -0.29022282 -0.3727752  -0.08953202  0.26552683 -0.48274752 -0.1702933\n",
      " -0.15829325  0.08267305 -0.07532632  0.1658448   0.38118345 -0.30057937\n",
      "  0.3094005   0.23786907 -0.20372514 -0.17284453  0.21302667  0.2881804\n",
      "  0.22022161  0.125137   -0.3144451  -0.28472728  0.3356436   0.16991864\n",
      "  0.21089107 -0.270978   -0.16533607 -0.23207633  0.08525473  0.15004292\n",
      "  0.45746714  0.23793383  0.3166437  -0.11305066 -0.30111915  0.14455763\n",
      "  0.2744459  -0.15565498  0.22402927  0.19261152 -0.3465789  -0.34627923\n",
      "  0.17655157 -0.16479553]\n"
     ]
    }
   ],
   "source": [
    "# example 2 : word vector for \"cat\"\n",
    "word_vector_cat = skip_gram_model.get_layer(\"context_embedding\").get_weights()[0][tokenizer.word_index[\"cat\"]]\n",
    "\n",
    "print(len(word_vector_cat))\n",
    "print(word_vector_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cd0cb51-4495-4c57-aeb0-c9cdcd35ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "[ 0.02534899  0.12047102  0.3764374  -0.07255813  0.51958036 -0.17348845\n",
      " -0.08853953  0.16519456  0.14518167  0.17024663  0.05739426 -0.15342963\n",
      "  0.12667334  0.00944092  0.42350096  0.22238661 -0.16007358  0.12519915\n",
      " -0.11583033 -0.35662946 -0.12330738 -0.20741612  0.14250234 -0.45800918\n",
      "  0.166765    0.15616044 -0.12254994  0.22289832 -0.04220576 -0.10405624\n",
      "  0.33918127 -0.51516974  0.48797056  0.03449334  0.1049895  -0.06961536\n",
      " -0.3008898  -0.24954242 -0.263484    0.2840222   0.06046656 -0.19347697\n",
      " -0.33714348 -0.01203065  0.21022484 -0.09915531  0.02330409  0.26657274\n",
      "  0.16765523  0.2313001  -0.13988364  0.2389606   0.03046129  0.22584376\n",
      "  0.06365097 -0.22275613  0.17984752 -0.12988643 -0.03387088  0.1413761\n",
      " -0.33251852  0.08744261 -0.1585932  -0.00141644  0.2432045   0.2246335\n",
      "  0.04431519 -0.05536337 -0.48505428  0.38819832  0.04292851  0.00095119\n",
      "  0.26299125  0.25060925  0.00234479 -0.24130784  0.20687337  0.04303828\n",
      " -0.19877939 -0.08837221  0.32335946 -0.26095125  0.11579531  0.12690146\n",
      " -0.20874298 -0.12515517 -0.05620867  0.4164594   0.01100969 -0.09699105\n",
      " -0.5562054   0.307978    0.1816294   0.2502692   0.09354639  0.08860289\n",
      "  0.00896451  0.38004693 -0.18593934 -0.45834798  0.2873956   0.28787982\n",
      "  0.05668184 -0.19178088 -0.18759784 -0.32476643  0.03290593  0.11018769\n",
      "  0.4288255  -0.24362943  0.06205081 -0.29618505  0.11423586  0.23123972\n",
      " -0.30249742 -0.0597908  -0.01243488 -0.3766222  -0.1437099   0.51967263\n",
      "  0.37782964 -0.18918578  0.28555968  0.07881864 -0.0619347  -0.03070746\n",
      "  0.15744127 -0.3668633 ]\n"
     ]
    }
   ],
   "source": [
    "# example 3 : word vector for \"man\"\n",
    "word_vector_man = skip_gram_model.get_layer(\"context_embedding\").get_weights()[0][tokenizer.word_index[\"man\"]]\n",
    "\n",
    "print(len(word_vector_man))\n",
    "print(word_vector_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd9ecf7c-a2e0-46af-bb2f-a471a21e69db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "[ 0.26309174  0.4147605   0.11572185  0.18393585  0.37184054 -0.18069829\n",
      " -0.19339332  0.17029996 -0.13269204  0.15365273 -0.283435   -0.19152485\n",
      "  0.34755978  0.11869116  0.08013584  0.16610299  0.22172268  0.4283985\n",
      " -0.17933767 -0.13001654 -0.41411307 -0.22224103  0.26052335 -0.3568804\n",
      "  0.26483512  0.212596   -0.3139042   0.38621023 -0.01998098 -0.1838497\n",
      " -0.1726185  -0.28903136  0.3464941   0.27167618  0.18794398  0.31031498\n",
      " -0.12902099 -0.18391809 -0.14488178  0.12919763  0.14627652 -0.3605748\n",
      " -0.23907977  0.0346491   0.02198527 -0.41710517  0.11936651 -0.20457141\n",
      " -0.24958594  0.21314938  0.21846868 -0.1826636  -0.3087275   0.36232403\n",
      "  0.38507396  0.23603722  0.181535   -0.30046725 -0.13386211  0.28226987\n",
      " -0.28213    -0.28206238  0.06141251 -0.07637422  0.04504185  0.3058593\n",
      "  0.22075182  0.20905247 -0.02321019  0.1084257   0.12345778 -0.09653618\n",
      "  0.26543063  0.23348318  0.14701082 -0.18342857  0.23847738  0.21532544\n",
      "  0.04154864 -0.37797916  0.15749688  0.3358833   0.23936018  0.41036546\n",
      " -0.28019723 -0.14449318 -0.19934474  0.37872428 -0.11113118 -0.2056101\n",
      " -0.26901332  0.26120082 -0.2433569   0.22472146  0.14624082 -0.09445785\n",
      "  0.19562952  0.07179435 -0.11676684 -0.37863994  0.30513173  0.27994892\n",
      "  0.21514168  0.10323705 -0.2857903  -0.4144728   0.22021104  0.2853856\n",
      "  0.3055989  -0.4196368  -0.5205213  -0.31110904  0.20718488  0.24565893\n",
      "  0.16629745  0.26350594  0.31806153 -0.20394662 -0.32292643  0.16238585\n",
      "  0.2865525  -0.19299118  0.25683942  0.28758016 -0.09695221 -0.1619444\n",
      "  0.13572425 -0.12860517]\n"
     ]
    }
   ],
   "source": [
    "# example 4 : word vector for \"woman\"\n",
    "word_vector_woman = skip_gram_model.get_layer(\"context_embedding\").get_weights()[0][tokenizer.word_index[\"woman\"]]\n",
    "\n",
    "print(len(word_vector_woman))\n",
    "print(word_vector_woman)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079a578-1136-454b-8879-b1159bb88e7a",
   "metadata": {},
   "source": [
    "# 16 . Usecase 2 : Similarity of the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc7b3553-d44e-4b6a-bf15-5202f4877329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45174366\n"
     ]
    }
   ],
   "source": [
    "# example 1 : similarity score between dog and cat\n",
    "similarity = np.dot(word_vector_dog, word_vector_cat) / (np.linalg.norm(word_vector_dog) * np.linalg.norm(word_vector_cat))\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2d63385-af43-4393-b22b-eed2db4ba393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38474867\n"
     ]
    }
   ],
   "source": [
    "# example 2 : similarity score between dog and man\n",
    "similarity = np.dot(word_vector_dog, word_vector_man) / (np.linalg.norm(word_vector_dog) * np.linalg.norm(word_vector_man))\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca817b83-7732-40ef-8d83-75bcb7340598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57171756\n"
     ]
    }
   ],
   "source": [
    "# example 3 : similarity score between woman and man\n",
    "similarity = np.dot(word_vector_man, word_vector_woman) / (np.linalg.norm(word_vector_man) * np.linalg.norm(word_vector_woman))\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ba9e0-7e17-46f6-b853-4fa559ffa66c",
   "metadata": {},
   "source": [
    "# 17. Usecase 3 : Analogy task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9001dc0-107c-4725-b48f-3b78b0bdea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "king_vector = skip_gram_model.get_layer(\"context_embedding\").get_weights()[0][tokenizer.word_index[\"king\"]]\n",
    "man_vector = skip_gram_model.get_layer(\"context_embedding\").get_weights()[0][tokenizer.word_index[\"man\"]]\n",
    "woman_vector = skip_gram_model.get_layer(\"context_embedding\").get_weights()[0][tokenizer.word_index[\"woman\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7317685-29cf-427d-861b-9250fedf86e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Queen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mword_index[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueen\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Queen'"
     ]
    }
   ],
   "source": [
    "tokenizer.word_index[\"Queen\"] ## doesnn't exist in the word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74aec59d-6398-40ea-acf8-6c5b7aa38b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "[ 3.3882433e-01  4.2410660e-01  2.2715658e-01  3.9626640e-01\n",
      "  1.3184062e-01 -4.4364864e-01 -3.5429621e-01  1.7759013e-01\n",
      " -6.3046116e-01  1.7294665e-01 -4.6839964e-01 -1.2489870e-02\n",
      "  3.5591775e-01  4.0181404e-01 -5.6488550e-01  1.4087935e-01\n",
      "  4.0124860e-01  3.9552587e-01 -2.9045260e-01  8.4689781e-02\n",
      " -4.7596377e-01 -1.8774298e-01  1.9676805e-01  7.4532449e-02\n",
      "  5.0112104e-01  4.7105271e-01 -4.3799841e-01  6.4600265e-01\n",
      " -6.5998752e-03  2.6150757e-01 -6.9362462e-01 -1.9329089e-01\n",
      "  1.0410756e-01  4.3062824e-01  2.3346071e-01  5.8081830e-01\n",
      " -2.0331767e-01 -5.8929153e-02  1.3925320e-01  4.3812141e-02\n",
      "  3.7249768e-01 -6.9328189e-02  3.1111437e-01 -1.0825166e-01\n",
      " -7.4586645e-04 -5.0805795e-01  2.0949735e-01 -5.0011224e-01\n",
      " -6.4535534e-01  2.7712733e-01  5.6053448e-01 -5.3525692e-01\n",
      " -6.4959365e-01  3.4441936e-01  6.3610405e-01  6.4036858e-01\n",
      "  1.7155142e-01 -3.7057552e-01 -8.2692251e-02  2.8188753e-01\n",
      "  1.2343082e-01 -4.7418472e-01  1.9500925e-01 -5.7620931e-01\n",
      " -2.2975923e-01  2.7805823e-01  2.7754918e-01  3.4062809e-01\n",
      "  5.8997792e-01 -4.9605437e-02  2.5650391e-01 -4.3438441e-01\n",
      "  2.7412915e-01  2.6918817e-01  3.5310835e-01 -2.3026267e-01\n",
      "  2.5610781e-01  2.4942379e-01  4.3496668e-02 -5.3066421e-01\n",
      "  3.0637354e-02  1.2355856e+00  2.6062068e-01  5.6801403e-01\n",
      " -4.2320991e-01 -7.6510191e-02 -1.7692477e-02  2.0757371e-01\n",
      " -5.8225495e-01 -3.2255572e-01  2.4261281e-01  6.4557746e-02\n",
      " -3.6174273e-01  4.7181392e-01  1.5008897e-01 -2.9789865e-01\n",
      "  5.4266709e-01 -2.5549698e-01 -2.0106830e-02  1.5407497e-01\n",
      "  2.0651802e-01  4.5090914e-02  3.8913029e-01  7.5894624e-01\n",
      " -6.7314130e-01 -2.2096705e-01  5.0473017e-01  2.2531341e-01\n",
      " -6.9254637e-04 -3.7834975e-01 -8.1969321e-01  9.8792195e-02\n",
      "  2.8470361e-01  1.2981638e-01  6.7101657e-01  3.5053384e-01\n",
      "  5.4098403e-01  1.3800189e-02 -5.7167232e-01 -3.4752581e-01\n",
      "  4.6309134e-01 -2.1678644e-01  1.7598087e-01  2.8997409e-01\n",
      " -3.3663893e-01 -2.9010427e-01  3.0491418e-01  3.8148612e-01]\n"
     ]
    }
   ],
   "source": [
    "# application of analogy to calculate Queen vector\n",
    "\n",
    "queen_vector = king_vector - man_vector + woman_vector\n",
    "print(len(queen_vector))\n",
    "print(queen_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad094cea-dcb2-4d75-8dd5-79fc1108eba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ad6de-fa4d-4fef-9b8f-5e9f4c63bb53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
